import { useState, useCallback, useRef, useEffect } from 'react';
import { log } from '../utils/logger';

const API_URL = import.meta.env.VITE_WORKERS_API_URL || 'https://api.languagemate.kr';

export function useRealtimeTranscription({
  language = 'auto',
  chunkDuration = 2000, // 2ì´ˆë§ˆë‹¤ ì²˜ë¦¬
  onTranscript,
  onError
} = {}) {
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [transcripts, setTranscripts] = useState([]);
  const [currentTranscript, setCurrentTranscript] = useState(null);
  const [error, setError] = useState(null);
  
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const processingRef = useRef(false);
  const chunkIntervalRef = useRef(null);
  const streamRef = useRef(null);

  // ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬
  const processAudioChunk = useCallback(async () => {
    if (audioChunksRef.current.length === 0 || processingRef.current) {
      if (audioChunksRef.current.length === 0) {
        console.log('â­ï¸ [useRealtimeTranscription] ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì—†ì–´ ì²˜ë¦¬ ê±´ë„ˆëœ€');
      }
      return;
    }
    
    processingRef.current = true;
    const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
    const blobSize = audioBlob.size;
    audioChunksRef.current = [];

    console.log('ğŸ“¤ [useRealtimeTranscription] ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ ì‹œì‘', {
      blobSize,
      language,
      apiUrl: `${API_URL}/api/v1/whisper/transcribe`
    });

    try {
      const formData = new FormData();
      formData.append('audio', audioBlob);
      formData.append('language', language);
      formData.append('task', 'transcribe');
      formData.append('vad_filter', 'true');
      formData.append('initial_prompt', 'This is a conversation between two people learning languages.');

      const response = await fetch(`${API_URL}/api/v1/whisper/transcribe`, {
        method: 'POST',
        body: formData
      });

      console.log('ğŸ“¥ [useRealtimeTranscription] API ì‘ë‹µ ìˆ˜ì‹ ', {
        status: response.status,
        statusText: response.statusText,
        ok: response.ok
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('âŒ [useRealtimeTranscription] API ì‘ë‹µ ì‹¤íŒ¨', {
          status: response.status,
          statusText: response.statusText,
          errorText
        });
        throw new Error(`Transcription failed: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('âœ… [useRealtimeTranscription] ì „ì‚¬ ê²°ê³¼ ìˆ˜ì‹ ', {
        hasText: !!result.text,
        textLength: result.text?.length,
        language: result.language,
        confidence: result.confidence
      });
      
      if (result.text && result.text.trim()) {
        const transcript = {
          id: `transcript-${Date.now()}`,
          text: result.text.trim(),
          timestamp: new Date().toISOString(),
          language: result.language || language,
          confidence: result.confidence,
          duration: result.duration,
          words: result.words
        };
        
        setCurrentTranscript(transcript);
        setTranscripts(prev => [...prev, transcript]);
        
        // ì½œë°± í˜¸ì¶œ
        if (onTranscript) {
          onTranscript(transcript);
        }
        
        // ì¼ì • ì‹œê°„ í›„ í˜„ì¬ ìë§‰ ì œê±°
        setTimeout(() => {
          setCurrentTranscript(prev => 
            prev?.id === transcript.id ? null : prev
          );
        }, 4000);
      }
    } catch (err) {
      const errorMessage = err.message || 'ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      setError(errorMessage);
      if (onError) {
        onError(err);
      }
    } finally {
      processingRef.current = false;
    }
  }, [language, onTranscript, onError]);

  // ë¯¸ë””ì–´ ë ˆì½”ë” ì´ˆê¸°í™”
  const initializeRecorder = useCallback(async (stream) => {
    // ìŠ¤íŠ¸ë¦¼ ê²€ì¦
    if (!stream || !(stream instanceof MediaStream)) {
      throw new Error('ìœ íš¨í•œ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }

    // ì˜¤ë””ì˜¤ íŠ¸ë™ë§Œ ì¶”ì¶œ
    const audioTracks = stream.getAudioTracks();
    
    // ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ê±°ë‚˜ ëª¨ë“  íŠ¸ë™ì´ ë¹„í™œì„±í™”ëœ ê²½ìš°
    if (audioTracks.length === 0) {
      throw new Error('ìŠ¤íŠ¸ë¦¼ì— ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ìŠµë‹ˆë‹¤.');
    }

    // í™œì„±í™”ëœ ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ìˆëŠ”ì§€ í™•ì¸
    const enabledTracks = audioTracks.filter(track => track.enabled && track.readyState === 'live');
    
    // í™œì„±í™”ëœ íŠ¸ë™ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ (ìë™ í™œì„±í™”í•˜ì§€ ì•ŠìŒ)
    // ì‚¬ìš©ìê°€ ì˜ë„ì ìœ¼ë¡œ ì˜¤ë””ì˜¤ë¥¼ ê»ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìë™ìœ¼ë¡œ ì¼œì§€ ì•ŠìŒ
    if (enabledTracks.length === 0) {
      throw new Error('ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ëª¨ë‘ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ë¥¼ ì¼œì£¼ì„¸ìš”.');
    }

    const audioStream = new MediaStream();
    enabledTracks.forEach(track => {
      audioStream.addTrack(track);
    });

    if (audioStream.getAudioTracks().length === 0) {
      throw new Error('ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }

    // MediaRecorder ì˜µì…˜ ì„¤ì •
    const options = {
      mimeType: 'audio/webm;codecs=opus',
      audioBitsPerSecond: 16000
    };

    // ì§€ì›ë˜ëŠ” MIME íƒ€ì… í™•ì¸
    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
      options.mimeType = 'audio/webm';
      if (!MediaRecorder.isTypeSupported(options.mimeType)) {
        throw new Error('ë¸Œë¼ìš°ì €ê°€ ì˜¤ë””ì˜¤ ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      }
    }

    const recorder = new MediaRecorder(audioStream, options);

    recorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunksRef.current.push(event.data);
      }
    };

    recorder.onstop = () => {
      processAudioChunk();
    };

    recorder.onerror = () => {
      const errorMessage = 'ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      setError(errorMessage);
      if (onError) {
        onError(new Error(errorMessage));
      }
    };

    return recorder;
  }, [processAudioChunk, onError]);

  // ì „ì‚¬ ì‹œì‘
  const startTranscription = useCallback(async (stream) => {
    console.log('ğŸ™ï¸ [useRealtimeTranscription] startTranscription í˜¸ì¶œë¨', {
      hasStream: !!stream,
      streamId: stream?.id
    });

    if (!stream) {
      console.warn('âš ï¸ [useRealtimeTranscription] ìŠ¤íŠ¸ë¦¼ì´ ì—†ì–´ ì „ì‚¬ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    // ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒíƒœ ì‚¬ì „ í™•ì¸
    const audioTracks = stream.getAudioTracks();
    console.log('ğŸµ [useRealtimeTranscription] ì˜¤ë””ì˜¤ íŠ¸ë™ í™•ì¸', {
      totalTracks: audioTracks.length,
      enabledTracks: audioTracks.filter(t => t.enabled && t.readyState === 'live').length,
      tracks: audioTracks.map(t => ({
        id: t.id,
        enabled: t.enabled,
        readyState: t.readyState,
        muted: t.muted
      }))
    });

    if (audioTracks.length === 0) {
      console.warn('âš ï¸ [useRealtimeTranscription] ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ì–´ ì „ì‚¬ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const enabledTracks = audioTracks.filter(track => track.enabled && track.readyState === 'live');
    if (enabledTracks.length === 0) {
      console.warn('âš ï¸ [useRealtimeTranscription] í™œì„±í™”ëœ ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ì–´ ì „ì‚¬ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ë¥¼ ì¼œì£¼ì„¸ìš”.');
      return;
    }

    try {
      setError(null);
      streamRef.current = stream;
      
      // ë ˆì½”ë” ì´ˆê¸°í™”
      const recorder = await initializeRecorder(stream);
      mediaRecorderRef.current = recorder;

      // ë…¹ìŒ ì‹œì‘
      recorder.start(250); // 250msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘

      // ì£¼ê¸°ì ìœ¼ë¡œ ì²­í¬ ì²˜ë¦¬ (ë” ë¹ˆë²ˆí•œ ì²˜ë¦¬ë¡œ ì§€ì—°ì‹œê°„ ê°ì†Œ)
      chunkIntervalRef.current = setInterval(() => {
        if (recorder.state === 'recording') {
          recorder.stop();
          recorder.start(250);
        }
      }, chunkDuration);

      setIsTranscribing(true);
      log.info('ì‹¤ì‹œê°„ ì „ì‚¬ ì‹œì‘', { language, chunkDuration }, 'TRANSCRIPTION');
      console.log('âœ… [useRealtimeTranscription] ì „ì‚¬ ì‹œì‘ ì„±ê³µ', {
        recorderState: recorder.state,
        language,
        chunkDuration
      });

    } catch (err) {
      // initializeRecorderì—ì„œ ë°œìƒí•œ ì—ëŸ¬ë§Œ ë¡œê¹… (ì˜¤ë””ì˜¤ íŠ¸ë™ ê´€ë ¨ ì—ëŸ¬ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨)
      const errorMessage = err.message || 'ì „ì‚¬ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      setError(errorMessage);
      log.error('ì „ì‚¬ ì‹œì‘ ì‹¤íŒ¨', err, 'TRANSCRIPTION');
      if (onError) {
        onError(err);
      }
    }
  }, [chunkDuration, initializeRecorder, onError, language]);

  // ì „ì‚¬ ì¤‘ì§€
  const stopTranscription = useCallback(() => {
    if (mediaRecorderRef.current?.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
    
    if (chunkIntervalRef.current) {
      clearInterval(chunkIntervalRef.current);
      chunkIntervalRef.current = null;
    }

    mediaRecorderRef.current = null;
    streamRef.current = null;
    audioChunksRef.current = [];
    processingRef.current = false;
    
    setIsTranscribing(false);
    setCurrentTranscript(null);
  }, []);

  // ì „ì‚¬ í† ê¸€
  const toggleTranscription = useCallback(async (stream) => {
    if (isTranscribing) {
      stopTranscription();
    } else {
      // ì „ì‚¬ ì‹œì‘ ì „ì— ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒíƒœ í™•ì¸
      if (stream) {
        const audioTracks = stream.getAudioTracks();
        const hasEnabledAudio = audioTracks.some(track => track.enabled && track.readyState === 'live');
        
        if (!hasEnabledAudio) {
          // ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ë°˜í™˜ (ì—ëŸ¬ ë¡œê·¸ ì—†ìŒ)
          return;
        }
      }
      
      await startTranscription(stream);
    }
  }, [isTranscribing, startTranscription, stopTranscription]);

  // ì „ì‚¬ ê¸°ë¡ ì´ˆê¸°í™”
  const clearTranscripts = useCallback(() => {
    setTranscripts([]);
    setCurrentTranscript(null);
  }, []);

  // ì „ì‚¬ ê¸°ë¡ ë‚´ë³´ë‚´ê¸°
  const exportTranscripts = useCallback((format = 'text') => {
    if (transcripts.length === 0) return null;

    if (format === 'text') {
      return transcripts.map(t => 
        `[${new Date(t.timestamp).toLocaleTimeString()}] ${t.text}`
      ).join('\n');
    }

    if (format === 'srt') {
      return transcripts.map((t, index) => {
        const startTime = new Date(t.timestamp);
        const endTime = new Date(startTime.getTime() + 4000);
        
        const formatTime = (date) => {
          const hours = String(date.getHours()).padStart(2, '0');
          const minutes = String(date.getMinutes()).padStart(2, '0');
          const seconds = String(date.getSeconds()).padStart(2, '0');
          const ms = String(date.getMilliseconds()).padStart(3, '0');
          return `${hours}:${minutes}:${seconds},${ms}`;
        };

        return `${index + 1}\n${formatTime(startTime)} --> ${formatTime(endTime)}\n${t.text}\n`;
      }).join('\n');
    }

    if (format === 'json') {
      return JSON.stringify(transcripts, null, 2);
    }

    return transcripts;
  }, [transcripts]);

  // í´ë¦°ì—…
  useEffect(() => {
    return () => {
      stopTranscription();
    };
  }, [stopTranscription]);

  return {
    // ìƒíƒœ
    isTranscribing,
    transcripts,
    currentTranscript,
    error,
    
    // ë©”ì„œë“œ
    startTranscription,
    stopTranscription,
    toggleTranscription,
    clearTranscripts,
    exportTranscripts,
    
    // í†µê³„
    stats: {
      totalTranscripts: transcripts.length,
      totalWords: transcripts.reduce((sum, t) => 
        sum + (t.text.split(' ').length || 0), 0
      ),
      duration: transcripts.reduce((sum, t) => 
        sum + (t.duration || 0), 0
      )
    }
  };
}
